{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3649,"databundleVersionId":46718,"sourceType":"competition"}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport shutil\nimport torch\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:03:50.045832Z","iopub.execute_input":"2024-03-20T15:03:50.046170Z","iopub.status.idle":"2024-03-20T15:03:53.575875Z","shell.execute_reply.started":"2024-03-20T15:03:50.046145Z","shell.execute_reply":"2024-03-20T15:03:53.574789Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install py7zr","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:01:19.702940Z","iopub.execute_input":"2024-03-20T15:01:19.703570Z","iopub.status.idle":"2024-03-20T15:01:44.892705Z","shell.execute_reply.started":"2024-03-20T15:01:19.703543Z","shell.execute_reply":"2024-03-20T15:01:44.891576Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting py7zr\n  Downloading py7zr-0.21.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\nCollecting pycryptodomex>=3.16.0 (from py7zr)\n  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting pyzstd>=0.15.9 (from py7zr)\n  Downloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\nCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting brotli>=1.1.0 (from py7zr)\n  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\nDownloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.15.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.3/412.3 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n  Attempting uninstall: brotli\n    Found existing installation: Brotli 1.0.9\n    Uninstalling Brotli-1.0.9:\n      Successfully uninstalled Brotli-1.0.9\nSuccessfully installed brotli-1.1.0 inflate64-1.0.0 multivolumefile-0.2.3 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.15.9\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfiles = os.listdir('/kaggle/working')\n\nfor file in files:\n    file_path = os.path.join('/kaggle/working', file)\n    if os.path.isfile(file_path):\n        os.remove(file_path)\n    else:\n        shutil.rmtree(file_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:03:58.100883Z","iopub.execute_input":"2024-03-20T15:03:58.101739Z","iopub.status.idle":"2024-03-20T15:03:58.107611Z","shell.execute_reply.started":"2024-03-20T15:03:58.101707Z","shell.execute_reply":"2024-03-20T15:03:58.106685Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from py7zr import unpack_7zarchive\n# unpack_7zarchive('/kaggle/input/cifar-10/train.7z', '/kaggle/working/train')\n# unpack_7zarchive('/kaggle/input/cifar-10/test.7z', '/kaggle/working/test')\n\nimport shutil\n\nshutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\nshutil.unpack_archive('/kaggle/input/cifar-10/train.7z', '/kaggle/temp/')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:04:16.107368Z","iopub.execute_input":"2024-03-20T15:04:16.107747Z","iopub.status.idle":"2024-03-20T15:04:44.317032Z","shell.execute_reply.started":"2024-03-20T15:04:16.107718Z","shell.execute_reply":"2024-03-20T15:04:44.316157Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_labels=pd.read_csv(\"/kaggle/input/cifar-10/trainLabels.csv\", header='infer')\nprint(train_labels.head(5))\nprint(train_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:06:01.466930Z","iopub.execute_input":"2024-03-20T15:06:01.467318Z","iopub.status.idle":"2024-03-20T15:06:01.511693Z","shell.execute_reply.started":"2024-03-20T15:06:01.467291Z","shell.execute_reply":"2024-03-20T15:06:01.510773Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"   id       label\n0   1        frog\n1   2       truck\n2   3       truck\n3   4        deer\n4   5  automobile\n(50000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\ntraindir = '/kaggle/temp/train'\n\n\nimage_filename = str(train_labels.iloc[0]['id']) + '.png'\nlabel = train_labels.iloc[0]['label']\nimage_path = os.path.join(traindir, image_filename)\n\nimage = Image.open(image_path)\nplt.figure(figsize=(2,2))\nplt.imshow(image)\nplt.title(f\"Label: {label}\")\nplt.axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:06:04.218394Z","iopub.execute_input":"2024-03-20T15:06:04.219059Z","iopub.status.idle":"2024-03-20T15:06:04.375064Z","shell.execute_reply.started":"2024-03-20T15:06:04.219030Z","shell.execute_reply":"2024-03-20T15:06:04.374028Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 200x200 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"labels=train_labels.iloc[:,-1].unique()\nprint(labels)\n\nname2num={}\ni=0\nfor name in labels:\n    name2num[name]=i\n    i=i+1\nprint(name2num)\nnum2name={}\nfor i in range(len(labels)):\n    num2name[i]=labels[i]\nprint(num2name)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:06:06.332956Z","iopub.execute_input":"2024-03-20T15:06:06.333584Z","iopub.status.idle":"2024-03-20T15:06:06.347778Z","shell.execute_reply.started":"2024-03-20T15:06:06.333552Z","shell.execute_reply":"2024-03-20T15:06:06.346940Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"['frog' 'truck' 'deer' 'automobile' 'bird' 'horse' 'ship' 'cat' 'dog'\n 'airplane']\n{'frog': 0, 'truck': 1, 'deer': 2, 'automobile': 3, 'bird': 4, 'horse': 5, 'ship': 6, 'cat': 7, 'dog': 8, 'airplane': 9}\n{0: 'frog', 1: 'truck', 2: 'deer', 3: 'automobile', 4: 'bird', 5: 'horse', 6: 'ship', 7: 'cat', 8: 'dog', 9: 'airplane'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# trainlabels=pd.read_csv('/kaggle/input/cifar-10/trainLabels.csv')\n# labels=trainlabels.iloc[:,-1].unique()\n# print(labels)\n# labels={}\n# count=1\n# for i in labels:\n#     labels[i]=count\n#     count+=1\n# print(labels)\n# labelid=list(labels.values())\n# print(labelid)\n# print(trainlabels.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device=torch.device(\"cuda\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:06:11.889913Z","iopub.execute_input":"2024-03-20T15:06:11.890507Z","iopub.status.idle":"2024-03-20T15:06:11.929384Z","shell.execute_reply.started":"2024-03-20T15:06:11.890475Z","shell.execute_reply":"2024-03-20T15:06:11.928310Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision.io import read_image\nfrom torchvision.transforms import ToTensor, Normalize, Resize, Compose\n\nclass TrainDataset(Dataset):\n    def __init__(self, imagepath, labelpath):\n        super().__init__()\n        self.imgpath=imagepath\n        self.labels=pd.read_csv(labelpath, header='infer')\n        self.transform=Compose([Resize((224,224)), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n        \n    def __len__(self):\n        return self.labels.shape[0]\n    \n    def __getitem__(self,index):\n        finalpath=os.path.join(self.imgpath,str(index+1))+'.png'\n        img=read_image(finalpath)/255\n        img=self.transform(img)\n        label=self.labels.iloc[index,1]\n        label=name2num[label]\n        return img,label\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:06:12.220930Z","iopub.execute_input":"2024-03-20T15:06:12.221777Z","iopub.status.idle":"2024-03-20T15:06:14.643820Z","shell.execute_reply.started":"2024-03-20T15:06:12.221745Z","shell.execute_reply":"2024-03-20T15:06:14.642843Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"traindataset=TrainDataset(traindir,'/kaggle/input/cifar-10/trainLabels.csv')        \n        \nbatch_size=64    \ntraindataloader=DataLoader(traindataset, batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:08:45.340231Z","iopub.execute_input":"2024-03-20T15:08:45.340630Z","iopub.status.idle":"2024-03-20T15:08:45.364933Z","shell.execute_reply.started":"2024-03-20T15:08:45.340600Z","shell.execute_reply":"2024-03-20T15:08:45.364120Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\nclass mobilenetv3(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.pretrainednet=mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT)\n        self.pretrainednet.classifier=nn.Sequential(\n            nn.Linear(in_features=960, out_features=1280, \n                   bias=True),nn.Hardswish(), \n            nn.Dropout(p=0.2, inplace=True), \n            nn.Linear(in_features=1280, out_features=10, \n                      bias=True)\n        )\n        \n    def forward(self,x):\n        x=self.pretrainednet(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:10:18.989320Z","iopub.execute_input":"2024-03-20T15:10:18.989710Z","iopub.status.idle":"2024-03-20T15:10:18.996790Z","shell.execute_reply.started":"2024-03-20T15:10:18.989681Z","shell.execute_reply":"2024-03-20T15:10:18.995626Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torchvision.models import vgg16, VGG16_Weights\n\nclass VGG16(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.pretrainednet=vgg16(weights=VGG16_Weights.DEFAULT)\n        self.pretrainednet.classifier=nn.Sequential(\n            nn.Linear(in_features=25088,out_features=4096,bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=4096,out_features=4096,bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=4096,out_features=1000,bias=True),\n            nn.ReLU(),\n            nn.Linear(in_features=1000,out_features=10,bias=True)\n        )\n    \n    def forward(self,x):\n        x=self.pretrainednet(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:10:44.806385Z","iopub.execute_input":"2024-03-20T15:10:44.807076Z","iopub.status.idle":"2024-03-20T15:10:44.815205Z","shell.execute_reply.started":"2024-03-20T15:10:44.807026Z","shell.execute_reply":"2024-03-20T15:10:44.814314Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nfrom torchvision.models import resnet18\nfrom torchvision.models.resnet import ResNet18_Weights\n\nclass Cifar10Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n#         self.pretrainednet = resnet18(pretrained=True)\n        self.pretrainednet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n        num_features = self.pretrainednet.fc.in_features\n        self.pretrainednet.fc = nn.Linear(num_features, 10)\n        \n    def forward(self, x):\n        x = self.pretrainednet(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:11:10.320659Z","iopub.execute_input":"2024-03-20T15:11:10.321490Z","iopub.status.idle":"2024-03-20T15:11:10.327497Z","shell.execute_reply.started":"2024-03-20T15:11:10.321457Z","shell.execute_reply":"2024-03-20T15:11:10.326558Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import resnet18\n\nmodel = resnet18(pretrained=True)  \nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:11:14.793422Z","iopub.execute_input":"2024-03-20T15:11:14.794156Z","iopub.status.idle":"2024-03-20T15:11:15.513817Z","shell.execute_reply.started":"2024-03-20T15:11:14.794125Z","shell.execute_reply":"2024-03-20T15:11:15.512913Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 138MB/s] ","output_type":"stream"},{"name":"stdout","text":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"models_acc={}\nmodels_loss={}","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:12:48.480577Z","iopub.execute_input":"2024-03-20T15:12:48.480954Z","iopub.status.idle":"2024-03-20T15:12:48.485446Z","shell.execute_reply.started":"2024-03-20T15:12:48.480902Z","shell.execute_reply":"2024-03-20T15:12:48.484483Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(dataloader, model,loss_fn, optimizer):\n    model.train()\n    track_loss=0\n    correct=0\n    \n    for i, (imgs, labels) in enumerate(dataloader):\n        imgs=imgs.to(device)\n        labels=labels.to(device)\n        pred=model(imgs)\n                    \n        loss=loss_fn(pred,labels)\n        track_loss+=loss.item()\n        correct+=(torch.argmax(pred,dim=1)==labels).type(torch.float).sum().item()\n        \n        running_loss=round(track_loss/(i+(imgs.shape[0]/batch_size)),2)\n        running_acc=round((correct/((i*batch_size+imgs.shape[0])))*100,2)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if i%100==0:\n            print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n            \n    epoch_loss=running_loss\n    epoch_acc=running_acc\n    return epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:13:17.031204Z","iopub.execute_input":"2024-03-20T15:13:17.031579Z","iopub.status.idle":"2024-03-20T15:13:17.040323Z","shell.execute_reply.started":"2024-03-20T15:13:17.031546Z","shell.execute_reply":"2024-03-20T15:13:17.039321Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = Cifar10Net()\nmodel = model.to(device)\n\nloss_fn = nn.CrossEntropyLoss()\nlr = 0.001\noptimizer = torch.optim.Adam(params=model.parameters(), lr=lr)\nepochs = 10\n\nprint(\"Training the newly added layers first\")\n\nfor i in range(epochs):\n    print(\"Epoch:\", i+1)\n    train_epoch_loss, train_epoch_acc = train_one_epoch(traindataloader, model, loss_fn, optimizer)\n    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n    print(\"--------------------------------------------------\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:19:35.724755Z","iopub.execute_input":"2024-03-20T15:19:35.725143Z","iopub.status.idle":"2024-03-20T15:28:24.985923Z","shell.execute_reply.started":"2024-03-20T15:19:35.725114Z","shell.execute_reply":"2024-03-20T15:28:24.984906Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Training the newly added layers first\nEpoch: 1\nBatch: 1 / 782 Running Loss: 2.68 Running Accuracy: 4.69\nBatch: 101 / 782 Running Loss: 0.91 Running Accuracy: 68.89\nBatch: 201 / 782 Running Loss: 0.78 Running Accuracy: 73.24\nBatch: 301 / 782 Running Loss: 0.71 Running Accuracy: 75.83\nBatch: 401 / 782 Running Loss: 0.65 Running Accuracy: 77.61\nBatch: 501 / 782 Running Loss: 0.62 Running Accuracy: 78.83\nBatch: 601 / 782 Running Loss: 0.59 Running Accuracy: 79.78\nBatch: 701 / 782 Running Loss: 0.57 Running Accuracy: 80.58\nTraining: Epoch Loss: 0.56 Epoch Accuracy: 81.04\n--------------------------------------------------\nEpoch: 2\nBatch: 1 / 782 Running Loss: 0.29 Running Accuracy: 92.19\nBatch: 101 / 782 Running Loss: 0.36 Running Accuracy: 87.86\nBatch: 201 / 782 Running Loss: 0.35 Running Accuracy: 88.14\nBatch: 301 / 782 Running Loss: 0.34 Running Accuracy: 88.51\nBatch: 401 / 782 Running Loss: 0.33 Running Accuracy: 88.87\nBatch: 501 / 782 Running Loss: 0.32 Running Accuracy: 89.13\nBatch: 601 / 782 Running Loss: 0.31 Running Accuracy: 89.4\nBatch: 701 / 782 Running Loss: 0.3 Running Accuracy: 89.59\nTraining: Epoch Loss: 0.3 Epoch Accuracy: 89.73\n--------------------------------------------------\nEpoch: 3\nBatch: 1 / 782 Running Loss: 0.21 Running Accuracy: 93.75\nBatch: 101 / 782 Running Loss: 0.22 Running Accuracy: 92.61\nBatch: 201 / 782 Running Loss: 0.23 Running Accuracy: 92.44\nBatch: 301 / 782 Running Loss: 0.23 Running Accuracy: 92.41\nBatch: 401 / 782 Running Loss: 0.22 Running Accuracy: 92.48\nBatch: 501 / 782 Running Loss: 0.21 Running Accuracy: 92.64\nBatch: 601 / 782 Running Loss: 0.21 Running Accuracy: 92.78\nBatch: 701 / 782 Running Loss: 0.2 Running Accuracy: 92.9\nTraining: Epoch Loss: 0.2 Epoch Accuracy: 93.03\n--------------------------------------------------\nEpoch: 4\nBatch: 1 / 782 Running Loss: 0.18 Running Accuracy: 93.75\nBatch: 101 / 782 Running Loss: 0.17 Running Accuracy: 94.43\nBatch: 201 / 782 Running Loss: 0.16 Running Accuracy: 94.55\nBatch: 301 / 782 Running Loss: 0.16 Running Accuracy: 94.69\nBatch: 401 / 782 Running Loss: 0.15 Running Accuracy: 94.8\nBatch: 501 / 782 Running Loss: 0.15 Running Accuracy: 94.89\nBatch: 601 / 782 Running Loss: 0.15 Running Accuracy: 94.92\nBatch: 701 / 782 Running Loss: 0.14 Running Accuracy: 95.05\nTraining: Epoch Loss: 0.14 Epoch Accuracy: 95.06\n--------------------------------------------------\nEpoch: 5\nBatch: 1 / 782 Running Loss: 0.06 Running Accuracy: 98.44\nBatch: 101 / 782 Running Loss: 0.12 Running Accuracy: 95.84\nBatch: 201 / 782 Running Loss: 0.12 Running Accuracy: 96.09\nBatch: 301 / 782 Running Loss: 0.11 Running Accuracy: 96.14\nBatch: 401 / 782 Running Loss: 0.11 Running Accuracy: 96.16\nBatch: 501 / 782 Running Loss: 0.11 Running Accuracy: 96.19\nBatch: 601 / 782 Running Loss: 0.11 Running Accuracy: 96.16\nBatch: 701 / 782 Running Loss: 0.11 Running Accuracy: 96.19\nTraining: Epoch Loss: 0.11 Epoch Accuracy: 96.27\n--------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"for param in model.pretrainednet.parameters():\n    param.requires_grad = True\n\nprint(\"Fine tuning in the entire model\")\n\nacc=[]\nloss=[]\nfor i in range(epochs):\n    print(\"Epoch:\", i + 1)\n    train_epoch_loss, train_epoch_acc = train_one_epoch(traindataloader, model, loss_fn, optimizer)\n    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n    print(\"--------------------------------------------------\")\n    acc.append(train_epoch_acc)\n    loss.append(train_epoch_loss)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T15:28:55.553574Z","iopub.execute_input":"2024-03-20T15:28:55.554422Z","iopub.status.idle":"2024-03-20T15:37:41.660001Z","shell.execute_reply.started":"2024-03-20T15:28:55.554385Z","shell.execute_reply":"2024-03-20T15:37:41.658829Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Fine tuning in the entire model\nEpoch: 1\nBatch: 1 / 782 Running Loss: 0.24 Running Accuracy: 95.31\nBatch: 101 / 782 Running Loss: 0.09 Running Accuracy: 96.86\nBatch: 201 / 782 Running Loss: 0.08 Running Accuracy: 97.16\nBatch: 301 / 782 Running Loss: 0.09 Running Accuracy: 97.1\nBatch: 401 / 782 Running Loss: 0.09 Running Accuracy: 96.88\nBatch: 501 / 782 Running Loss: 0.09 Running Accuracy: 96.91\nBatch: 601 / 782 Running Loss: 0.09 Running Accuracy: 96.83\nBatch: 701 / 782 Running Loss: 0.09 Running Accuracy: 96.91\nTraining: Epoch Loss: 0.09 Epoch Accuracy: 96.98\n--------------------------------------------------\nEpoch: 2\nBatch: 1 / 782 Running Loss: 0.08 Running Accuracy: 96.88\nBatch: 101 / 782 Running Loss: 0.08 Running Accuracy: 97.22\nBatch: 201 / 782 Running Loss: 0.08 Running Accuracy: 97.43\nBatch: 301 / 782 Running Loss: 0.08 Running Accuracy: 97.22\nBatch: 401 / 782 Running Loss: 0.08 Running Accuracy: 97.19\nBatch: 501 / 782 Running Loss: 0.08 Running Accuracy: 97.27\nBatch: 601 / 782 Running Loss: 0.08 Running Accuracy: 97.27\nBatch: 701 / 782 Running Loss: 0.08 Running Accuracy: 97.35\nTraining: Epoch Loss: 0.08 Epoch Accuracy: 97.4\n--------------------------------------------------\nEpoch: 3\nBatch: 1 / 782 Running Loss: 0.04 Running Accuracy: 98.44\nBatch: 101 / 782 Running Loss: 0.06 Running Accuracy: 97.68\nBatch: 201 / 782 Running Loss: 0.06 Running Accuracy: 97.78\nBatch: 301 / 782 Running Loss: 0.07 Running Accuracy: 97.66\nBatch: 401 / 782 Running Loss: 0.07 Running Accuracy: 97.58\nBatch: 501 / 782 Running Loss: 0.07 Running Accuracy: 97.64\nBatch: 601 / 782 Running Loss: 0.07 Running Accuracy: 97.69\nBatch: 701 / 782 Running Loss: 0.06 Running Accuracy: 97.75\nTraining: Epoch Loss: 0.06 Epoch Accuracy: 97.74\n--------------------------------------------------\nEpoch: 4\nBatch: 1 / 782 Running Loss: 0.04 Running Accuracy: 98.44\nBatch: 101 / 782 Running Loss: 0.06 Running Accuracy: 98.13\nBatch: 201 / 782 Running Loss: 0.06 Running Accuracy: 98.13\nBatch: 301 / 782 Running Loss: 0.06 Running Accuracy: 98.06\nBatch: 401 / 782 Running Loss: 0.06 Running Accuracy: 98.02\nBatch: 501 / 782 Running Loss: 0.05 Running Accuracy: 98.12\nBatch: 601 / 782 Running Loss: 0.06 Running Accuracy: 98.11\nBatch: 701 / 782 Running Loss: 0.06 Running Accuracy: 98.14\nTraining: Epoch Loss: 0.06 Epoch Accuracy: 98.13\n--------------------------------------------------\nEpoch: 5\nBatch: 1 / 782 Running Loss: 0.05 Running Accuracy: 98.44\nBatch: 101 / 782 Running Loss: 0.04 Running Accuracy: 98.38\nBatch: 201 / 782 Running Loss: 0.05 Running Accuracy: 98.17\nBatch: 301 / 782 Running Loss: 0.05 Running Accuracy: 98.19\nBatch: 401 / 782 Running Loss: 0.05 Running Accuracy: 98.2\nBatch: 501 / 782 Running Loss: 0.05 Running Accuracy: 98.26\nBatch: 601 / 782 Running Loss: 0.05 Running Accuracy: 98.24\nBatch: 701 / 782 Running Loss: 0.05 Running Accuracy: 98.27\nTraining: Epoch Loss: 0.05 Epoch Accuracy: 98.28\n--------------------------------------------------\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch Loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_epoch_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_epoch_acc)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m models_acc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43macc\u001b[49m\n\u001b[1;32m     12\u001b[0m models_loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mloss\n","\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"],"ename":"NameError","evalue":"name 'acc' is not defined","output_type":"error"}]},{"cell_type":"code","source":"models_acc['resnet']=acc\nmodels_loss['resnet']=loss","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:36:20.396012Z","iopub.execute_input":"2024-03-20T16:36:20.396929Z","iopub.status.idle":"2024-03-20T16:36:20.401115Z","shell.execute_reply.started":"2024-03-20T16:36:20.396887Z","shell.execute_reply":"2024-03-20T16:36:20.400159Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"modelv=VGG16().to(device)\n\nfor param in modelv.pretrainednet.features.parameters():\n    param.requires_grad=True\n\nacc=[]\nloss=[]\nepochs=10\nfor i in range(epochs):\n    print(\"Epoch No:\",i+1)\n    train_epoch_loss, train_epoch_acc=train_one_epoch(traindataloader,modelv,loss_fn,optimizer)\n    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n    print(\"--------------------------------------------------\")\n    acc.append(train_epoch_acc)\n    loss.append(train_epoch_loss)\n    \nmodels_acc['VGG16']=acc\nmodels_loss['VGG16']=loss","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:46:32.367052Z","iopub.execute_input":"2024-03-20T16:46:32.367773Z","iopub.status.idle":"2024-03-20T16:58:27.559867Z","shell.execute_reply.started":"2024-03-20T16:46:32.367740Z","shell.execute_reply":"2024-03-20T16:58:27.558901Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch No: 1\nBatch: 1 / 782 Running Loss: 2.31 Running Accuracy: 3.12\nBatch: 101 / 782 Running Loss: 2.3 Running Accuracy: 10.19\nBatch: 201 / 782 Running Loss: 2.3 Running Accuracy: 10.19\nBatch: 301 / 782 Running Loss: 2.3 Running Accuracy: 10.23\nBatch: 401 / 782 Running Loss: 2.3 Running Accuracy: 10.17\nBatch: 501 / 782 Running Loss: 2.3 Running Accuracy: 10.15\nBatch: 601 / 782 Running Loss: 2.3 Running Accuracy: 10.11\nBatch: 701 / 782 Running Loss: 2.3 Running Accuracy: 10.09\nTraining: Epoch Loss: 2.31 Epoch Accuracy: 10.06\n--------------------------------------------------\nEpoch No: 2\nBatch: 1 / 782 Running Loss: 2.31 Running Accuracy: 3.12\nBatch: 101 / 782 Running Loss: 2.3 Running Accuracy: 10.19\nBatch: 201 / 782 Running Loss: 2.3 Running Accuracy: 10.19\nBatch: 301 / 782 Running Loss: 2.3 Running Accuracy: 10.23\nBatch: 401 / 782 Running Loss: 2.3 Running Accuracy: 10.17\nBatch: 501 / 782 Running Loss: 2.3 Running Accuracy: 10.15\nBatch: 601 / 782 Running Loss: 2.3 Running Accuracy: 10.11\nBatch: 701 / 782 Running Loss: 2.3 Running Accuracy: 10.09\nTraining: Epoch Loss: 2.31 Epoch Accuracy: 10.06\n--------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"modelv3=mobilenetv3().to(device)\n\nfor param in modelv3.pretrainednet.features.parameters():\n    param.requires_grad=True\n\nepochs=10\nacc=[]\nloss=[]\nfor i in range(epochs):\n    print(\"Epoch No:\",i+1)\n    train_epoch_loss, train_epoch_acc=train_one_epoch(traindataloader,modelv3,loss_fn,optimizer)\n    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n    print(\"--------------------------------------------------\")\n    acc.append(train_epoch_acc)\n    loss.append(train_epoch_loss)\n    \nmodels_acc['mobilenetv3']=acc\nmodels_loss['mobilenetv3']=loss","metadata":{"execution":{"iopub.status.busy":"2024-03-20T16:58:27.561570Z","iopub.execute_input":"2024-03-20T16:58:27.561880Z","iopub.status.idle":"2024-03-20T17:02:14.274783Z","shell.execute_reply.started":"2024-03-20T16:58:27.561853Z","shell.execute_reply":"2024-03-20T17:02:14.273807Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Epoch No: 1\nBatch: 1 / 782 Running Loss: 2.3 Running Accuracy: 12.5\nBatch: 101 / 782 Running Loss: 2.3 Running Accuracy: 9.81\nBatch: 201 / 782 Running Loss: 2.3 Running Accuracy: 9.38\nBatch: 301 / 782 Running Loss: 2.3 Running Accuracy: 9.43\nBatch: 401 / 782 Running Loss: 2.3 Running Accuracy: 9.24\nBatch: 501 / 782 Running Loss: 2.3 Running Accuracy: 9.32\nBatch: 601 / 782 Running Loss: 2.3 Running Accuracy: 9.36\nBatch: 701 / 782 Running Loss: 2.3 Running Accuracy: 9.4\nTraining: Epoch Loss: 2.31 Epoch Accuracy: 9.41\n--------------------------------------------------\nEpoch No: 2\nBatch: 1 / 782 Running Loss: 2.31 Running Accuracy: 7.81\nBatch: 101 / 782 Running Loss: 2.3 Running Accuracy: 9.51\nBatch: 201 / 782 Running Loss: 2.3 Running Accuracy: 9.31\nBatch: 301 / 782 Running Loss: 2.3 Running Accuracy: 9.33\nBatch: 401 / 782 Running Loss: 2.3 Running Accuracy: 9.07\nBatch: 501 / 782 Running Loss: 2.3 Running Accuracy: 9.17\nBatch: 601 / 782 Running Loss: 2.3 Running Accuracy: 9.25\nBatch: 701 / 782 Running Loss: 2.3 Running Accuracy: 9.27\nTraining: Epoch Loss: 2.31 Epoch Accuracy: 9.28\n--------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(\"for Resnet18 accuracy: \",max(model_acc['resnet']))\n# print(\"for vgg16 accuracy: \",max(model_acc['VGG16']))\n# print(\"for mobilenetv3 accuracy: \",max(model_acc['mobilenetv3']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdir='/kaggle/working/test'\nshutil.unpack_archive('/kaggle/input/cifar-10/test.7z', testdir)\nshutil.unregister_unpack_format('7zip')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:07:38.721101Z","iopub.execute_input":"2024-03-20T17:07:38.722055Z","iopub.status.idle":"2024-03-20T17:10:46.270392Z","shell.execute_reply.started":"2024-03-20T17:07:38.722022Z","shell.execute_reply":"2024-03-20T17:10:46.269558Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"testdir='/kaggle/working/test/test'\nimage_files = os.listdir(testdir)\nimage_file = os.path.join(testdir, image_files[0])\nimage = Image.open(image_file)\n\nplt.figure(figsize=(2, 2))\nplt.imshow(image)\nplt.axis('off') \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:10:46.272066Z","iopub.execute_input":"2024-03-20T17:10:46.272505Z","iopub.status.idle":"2024-03-20T17:10:46.488123Z","shell.execute_reply.started":"2024-03-20T17:10:46.272472Z","shell.execute_reply":"2024-03-20T17:10:46.486561Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 200x200 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, imgpath):\n        super().__init__()\n        self.imgpath=imgpath\n        _,_,self.files=next(os.walk(self.imgpath))\n        self.length=len(self.files)\n        self.transform=Compose([Resize((224,224), antialias=True), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])        \n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self,index):\n        finalpath=os.path.join(self.imgpath,str(index+1))+'.png'\n        img=read_image(finalpath)/255.0\n        img=self.transform(img)\n        return img\n\ntestdataset=TestDataset(testdir)\ntestdataloader=DataLoader(dataset=testdataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:10:46.489873Z","iopub.execute_input":"2024-03-20T17:10:46.491013Z","iopub.status.idle":"2024-03-20T17:10:46.914319Z","shell.execute_reply.started":"2024-03-20T17:10:46.490969Z","shell.execute_reply":"2024-03-20T17:10:46.913542Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def eval(dataloader, model,loss_fn, path):\n    model.eval()\n    data=pd.read_csv(path)\n    with torch.no_grad():\n        for i, imgs in enumerate(dataloader):\n            finalbatchpred=np.zeros(imgs.shape[0],dtype='object')\n            imgs=imgs.to(device)\n            pred=model(imgs)\n            \n            pred=torch.argmax(pred,dim=1).type(torch.int).cpu()\n            for j,p in enumerate(pred):\n                finalbatchpred[j]=num2name[p.item()]\n            data.iloc[i*batch_size:i*batch_size+batch_size ,1]=finalbatchpred\n    \n    data.to_csv('submission.csv', index=False)\n    print(data.head(10))","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:10:46.916563Z","iopub.execute_input":"2024-03-20T17:10:46.916925Z","iopub.status.idle":"2024-03-20T17:10:46.924572Z","shell.execute_reply.started":"2024-03-20T17:10:46.916893Z","shell.execute_reply":"2024-03-20T17:10:46.923710Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"eval(testdataloader, model,loss_fn, '/kaggle/input/cifar-10/sampleSubmission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:10:46.925631Z","iopub.execute_input":"2024-03-20T17:10:46.925920Z","iopub.status.idle":"2024-03-20T17:18:39.218221Z","shell.execute_reply.started":"2024-03-20T17:10:46.925898Z","shell.execute_reply":"2024-03-20T17:18:39.217222Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"   id     label\n0   1     horse\n1   2      deer\n2   3  airplane\n3   4  airplane\n4   5      deer\n5   6      deer\n6   7      ship\n7   8      deer\n8   9       dog\n9  10      deer\n","output_type":"stream"}]},{"cell_type":"code","source":"df=pd.read_csv('submission.csv')\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:18:39.219895Z","iopub.execute_input":"2024-03-20T17:18:39.220205Z","iopub.status.idle":"2024-03-20T17:18:39.304055Z","shell.execute_reply.started":"2024-03-20T17:18:39.220179Z","shell.execute_reply":"2024-03-20T17:18:39.303089Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"   id     label\n0   1     horse\n1   2      deer\n2   3  airplane\n3   4  airplane\n4   5      deer","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>horse</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>deer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>airplane</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>deer</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}