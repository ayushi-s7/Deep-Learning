{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import datasets\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom torchvision.transforms import ToTensor\nfrom matplotlib import pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-28T19:23:17.902446Z","iopub.execute_input":"2024-04-28T19:23:17.903316Z","iopub.status.idle":"2024-04-28T19:23:17.908230Z","shell.execute_reply.started":"2024-04-28T19:23:17.903281Z","shell.execute_reply":"2024-04-28T19:23:17.907165Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device=torch.device(type='cuda')\nelse:\n    device=torch.device(type='cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:23:18.385490Z","iopub.execute_input":"2024-04-28T19:23:18.385794Z","iopub.status.idle":"2024-04-28T19:23:18.391224Z","shell.execute_reply.started":"2024-04-28T19:23:18.385771Z","shell.execute_reply":"2024-04-28T19:23:18.390399Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset=datasets.MNIST(root=\"/kaggle/temp/\",\n                            train=True,\n                            download=True,\n                            transform=ToTensor())\n\neval_dataset=datasets.MNIST(root=\"/kaggle/temp/\",\n                            train=False,\n                            download=True,\n                            transform=ToTensor())","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:23:45.385832Z","iopub.execute_input":"2024-04-28T19:23:45.386558Z","iopub.status.idle":"2024-04-28T19:23:45.470093Z","shell.execute_reply.started":"2024-04-28T19:23:45.386526Z","shell.execute_reply":"2024-04-28T19:23:45.469288Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"batch_size=64","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:23:57.056038Z","iopub.execute_input":"2024-04-28T19:23:57.056677Z","iopub.status.idle":"2024-04-28T19:23:57.060718Z","shell.execute_reply.started":"2024-04-28T19:23:57.056639Z","shell.execute_reply":"2024-04-28T19:23:57.059757Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"train_dataloader=DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\neval_dataloader=DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:24:05.476139Z","iopub.execute_input":"2024-04-28T19:24:05.476546Z","iopub.status.idle":"2024-04-28T19:24:05.486598Z","shell.execute_reply.started":"2024-04-28T19:24:05.476513Z","shell.execute_reply":"2024-04-28T19:24:05.485434Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"class Encoder1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lkrelu=nn.LeakyReLU(0.1)\n        self.l1=nn.Linear(in_features=784,out_features=512)\n        self.l2=nn.Linear(in_features=512,out_features=256)\n    \n    def forward(self,x):\n        net1=self.l1(x)\n        out1=self.lkrelu(net1)\n        net2=self.l2(out1)\n        out2=self.lkrelu(net2)\n        return out2","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:24:55.444234Z","iopub.execute_input":"2024-04-28T19:24:55.444997Z","iopub.status.idle":"2024-04-28T19:24:55.452555Z","shell.execute_reply.started":"2024-04-28T19:24:55.444964Z","shell.execute_reply":"2024-04-28T19:24:55.451230Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"class Decoder1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lkrelu=nn.LeakyReLU(0.1)\n        self.sig=nn.Sigmoid()\n        self.l1=nn.Linear(in_features=256,out_features=512)\n        self.l2=nn.Linear(in_features=512,out_features=784)\n    \n    def forward(self,x):\n        net1=self.l1(x)\n        out1=self.lkrelu(net1)\n        net2=self.l2(out1)\n        out2=self.sig(net2)\n        return out2","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:25:09.933329Z","iopub.execute_input":"2024-04-28T19:25:09.934035Z","iopub.status.idle":"2024-04-28T19:25:09.940283Z","shell.execute_reply.started":"2024-04-28T19:25:09.934002Z","shell.execute_reply":"2024-04-28T19:25:09.939418Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"class Encoder2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lkrelu=nn.LeakyReLU(0.1)\n        self.l1=nn.Linear(in_features=256,out_features=100)\n            \n    def forward(self,x):\n        net1=self.l1(x)\n        out1=self.lkrelu(net1)\n        return out1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lkrelu=nn.LeakyReLU(0.1)\n        self.l1=nn.Linear(in_features=100,out_features=256)\n            \n    def forward(self,x):\n        net1=self.l1(x)\n        out1=self.lkrelu(net1)\n        return out1","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:25:31.444661Z","iopub.execute_input":"2024-04-28T19:25:31.445139Z","iopub.status.idle":"2024-04-28T19:25:31.451702Z","shell.execute_reply.started":"2024-04-28T19:25:31.445099Z","shell.execute_reply":"2024-04-28T19:25:31.450763Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.out=nn.Linear(in_features=100,out_features=10)\n    \n    def forward(self,x):\n        out=self.out(x)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:25:37.368097Z","iopub.execute_input":"2024-04-28T19:25:37.368763Z","iopub.status.idle":"2024-04-28T19:25:37.374024Z","shell.execute_reply.started":"2024-04-28T19:25:37.368722Z","shell.execute_reply":"2024-04-28T19:25:37.373039Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"lossmse_fn=nn.MSELoss()\nlossentropy_fn=nn.CrossEntropyLoss()\nlr=0.001","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:25:48.422495Z","iopub.execute_input":"2024-04-28T19:25:48.423252Z","iopub.status.idle":"2024-04-28T19:25:48.427574Z","shell.execute_reply.started":"2024-04-28T19:25:48.423216Z","shell.execute_reply":"2024-04-28T19:25:48.426524Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"e1=Encoder1().to(device)\nd1=Decoder1().to(device)\ne2=Encoder2().to(device)\nd2=Decoder2().to(device)\nclf=Classifier().to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:25:58.631292Z","iopub.execute_input":"2024-04-28T19:25:58.632120Z","iopub.status.idle":"2024-04-28T19:25:58.649623Z","shell.execute_reply.started":"2024-04-28T19:25:58.632087Z","shell.execute_reply":"2024-04-28T19:25:58.648899Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"opte1=Adam(params=e1.parameters(),lr=lr)\noptd1=Adam(params=d1.parameters(),lr=lr)\nopte2=Adam(params=e2.parameters(),lr=lr)\noptd2=Adam(params=d2.parameters(),lr=lr)\noptclf=Adam(params=clf.parameters(),lr=lr)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:26:05.589860Z","iopub.execute_input":"2024-04-28T19:26:05.590563Z","iopub.status.idle":"2024-04-28T19:26:05.597020Z","shell.execute_reply.started":"2024-04-28T19:26:05.590529Z","shell.execute_reply":"2024-04-28T19:26:05.596125Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"#train AutoEncoder1\ndef train_e1d1():    \n    track_loss=0\n    e1.train()\n    d1.train()\n    \n    for i,(x,y) in enumerate(train_dataloader):\n        x=torch.reshape(x,shape=(-1,784))\n        x=x.to(device)\n        latent=e1(x)\n        pred=d1(latent)\n        loss=lossmse_fn(pred,x)   \n        track_loss+=loss.item()     \n        loss.backward() \n        opte1.step()\n        optd1.step()  \n        opte1.zero_grad()\n        optd1.zero_grad()\n        \n        running_loss=track_loss/(i+(x.shape[0]/batch_size))\n            \n    return round(running_loss,4)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:24:17.568437Z","iopub.execute_input":"2024-04-28T19:24:17.568775Z","iopub.status.idle":"2024-04-28T19:24:17.590247Z","shell.execute_reply.started":"2024-04-28T19:24:17.568751Z","shell.execute_reply":"2024-04-28T19:24:17.589222Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"#train AutoEncoder2\ndef train_e2d2():    \n    track_loss=0\n    \n    e2.train()\n    d2.train()\n    \n    for i,(x,y) in enumerate(train_dataloader):\n        x=torch.reshape(x,shape=(-1,784))\n        x=x.to(device)\n        latente1=e1(x)\n        latente2=e2(latente1.detach())\n        pred=d2(latente2)\n        loss=lossmse_fn(pred,latente1.detach()) \n        track_loss+=loss.item()\n        loss.backward()\n        opte2.step()\n        optd2.step()\n        opte2.zero_grad()\n        optd2.zero_grad()\n        \n        running_loss=track_loss/(i+(x.shape[0]/batch_size))\n    \n    return round(running_loss,4)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:28:09.360248Z","iopub.execute_input":"2024-04-28T19:28:09.360628Z","iopub.status.idle":"2024-04-28T19:28:09.367978Z","shell.execute_reply.started":"2024-04-28T19:28:09.360599Z","shell.execute_reply":"2024-04-28T19:28:09.367064Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"#train Classifier\ndef train_clf():  \n    track_loss=0\n    num_correct=0\n    clf.train()\n    for i,(x,y) in enumerate(train_dataloader):\n        x=torch.reshape(x,shape=(-1,784))\n        x=x.to(device)\n        y=y.to(device)\n        latente1=e1(x)\n        latente2=e2(latente1)\n        pred=clf(latente2.detach())\n        num_correct+=(torch.argmax(pred,dim=1)==y).type(torch.float).sum().item()\n        loss=lossentropy_fn(pred,y)\n        track_loss+=loss.item()\n        loss.backward()\n        optclf.step()\n        optclf.zero_grad()\n        running_loss=track_loss/(i+(x.shape[0]/batch_size))\n        running_acc=(num_correct/((i*batch_size+x.shape[0])))*100\n    \n    return round(running_loss,4), round(running_acc,2)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:28:30.107554Z","iopub.execute_input":"2024-04-28T19:28:30.108220Z","iopub.status.idle":"2024-04-28T19:28:30.116188Z","shell.execute_reply.started":"2024-04-28T19:28:30.108186Z","shell.execute_reply":"2024-04-28T19:28:30.115174Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"#finetune whole \ndef train_whole():\n    track_loss=0\n    num_correct=0\n    e1.train()\n    e2.train()\n    clf.train()\n    for i,(x,y) in enumerate(train_dataloader):\n        x=torch.reshape(x,shape=(-1,784))\n        x=x.to(device)\n        y=y.to(device)\n        latente1=e1(x)\n        latente2=e2(latente1)\n        pred=clf(latente2)\n        num_correct+=(torch.argmax(pred,dim=1)==y).type(torch.float).sum().item()\n        loss=lossentropy_fn(pred,y)\n        track_loss+=loss.item()\n        loss.backward()\n        opte1.step()\n        opte2.step()\n        optclf.step()\n        opte1.zero_grad()\n        opte2.zero_grad()\n        optclf.zero_grad()\n        \n        running_loss=track_loss/(i+(x.shape[0]/batch_size))\n        running_acc=(num_correct/((i*batch_size+x.shape[0])))*100\n    \n    return round(running_loss,4),round(running_acc,2)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:28:55.367813Z","iopub.execute_input":"2024-04-28T19:28:55.368557Z","iopub.status.idle":"2024-04-28T19:28:55.377154Z","shell.execute_reply.started":"2024-04-28T19:28:55.368524Z","shell.execute_reply":"2024-04-28T19:28:55.376258Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"#Eval AutoEncoder1\ndef eval_e1d1():\n    \n    track_loss=0\n    \n    e1.eval()\n    d1.eval()\n    \n    with torch.no_grad():\n        for i,(x,y) in enumerate(eval_dataloader):\n            x=torch.reshape(x,shape=(-1,784))\n            x=x.to(device)\n\n            latent=e1(x)\n            pred=d1(latent)\n\n            loss=lossmse_fn(pred,x)\n            track_loss+=loss.item()\n            \n            running_loss=track_loss/(i+(x.shape[0]/batch_size))\n    \n    return round(running_loss,4),x,pred\n\n#Eval AutoEncoder2\ndef eval_e2d2():\n    track_loss=0\n    \n    e2.eval()\n    d2.eval()\n    \n    with torch.no_grad():\n        for i,(x,y) in enumerate(eval_dataloader):\n            x=torch.reshape(x,shape=(-1,784))\n            x=x.to(device)\n\n            latente1=e1(x)\n            latente2=e2(latente1)\n            pred=d2(latente2)\n\n            loss=lossmse_fn(pred,latente1)\n            \n            track_loss+=loss.item()\n            \n            running_loss=track_loss/(i+(x.shape[0]/batch_size))\n    \n    return round(running_loss,4)\n            \n        \n#Eval Classifier\ndef eval_clf():\n    track_loss=0\n    num_correct=0\n    \n    clf.eval()\n    \n    with torch.no_grad():\n        for i,(x,y) in enumerate(eval_dataloader):\n            x=torch.reshape(x,shape=(-1,784))\n            x=x.to(device)\n            y=y.to(device)\n\n            latente1=e1(x)\n            latente2=e2(latente1)\n            pred=clf(latente2)\n            \n            num_correct+=(torch.argmax(pred,dim=1)==y).type(torch.float).sum().item()\n            running_acc=(num_correct/((i*batch_size+x.shape[0])))*100\n            \n            loss=lossentropy_fn(pred,y)\n            track_loss+=loss.item()\n            \n            running_loss=track_loss/(i+(x.shape[0]/batch_size))\n            \n    \n    return round(running_loss,4), round(running_acc,2)\n        \n#eval whole \ndef eval_whole():\n    track_loss=0\n    num_correct=0\n    \n    e1.eval()\n    e2.eval()\n    clf.eval()\n    with torch.no_grad():\n        for i,(x,y) in enumerate(eval_dataloader):\n            x=torch.reshape(x,shape=(-1,784))\n            x=x.to(device)\n            y=y.to(device)\n\n            latente1=e1(x)\n            latente2=e2(latente1)\n            pred=clf(latente2)\n            \n            num_correct+=(torch.argmax(pred,dim=1)==y).type(torch.float).sum().item()\n            running_acc=(num_correct/((i*batch_size+x.shape[0])))*100\n            \n            loss=lossentropy_fn(pred,y)\n            track_loss+=loss.item()\n            \n            running_loss=track_loss/(i+(x.shape[0]/batch_size))\n    \n    return round(running_loss,4), round(running_acc,2)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:29:01.641633Z","iopub.execute_input":"2024-04-28T19:29:01.642000Z","iopub.status.idle":"2024-04-28T19:29:01.662156Z","shell.execute_reply.started":"2024-04-28T19:29:01.641971Z","shell.execute_reply":"2024-04-28T19:29:01.661235Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"n_epochs=20\n\nprint(\"-----------------------Auto Encoder 1------------------------\")\nfor i in range(n_epochs):\n    train_loss=train_e1d1()\n    eval_loss,x,pred=eval_e1d1()\n    print(\"Epoch=\", i+1,\", Train Loss=\",train_loss,\", Eval Loss=\",eval_loss,sep=\"\")\n    \nplt.figure(figsize=(3.2,2.4))\n\nr=torch.randint(low=0,high=pred.shape[0],size=(1,)).item()\n\nplt.subplot(1,2,1)\nplt.title(\"Orignal\")\nplt.imshow(torch.reshape(x[r],shape=(28,28)).cpu())\n\nplt.subplot(1,2,2)\nplt.title(\"Prediction\")\nplt.imshow(torch.reshape(pred[r],shape=(28,28)).cpu())\nplt.show()\n    \nprint(\"-----------------------Auto Encoder 2------------------------\")\nfor i in range(n_epochs):\n    print(\"Epoch=\", i+1,\", Train Loss=\",train_e2d2(),\", Eval Loss=\",eval_e2d2(),sep=\"\") \n\n\nprint(\"-----------------------Classifier Only------------------------\")\nfor i in range(n_epochs):\n    print(\"Epoch=\", i+1,\", Train Loss & Accuracy=\",train_clf(),\", Eval Loss & Accuracy=\",eval_clf(),sep=\"\") \n\n\nprint(\"--------------------Fine-Tuning Whole Network------------------\")\nfor i in range(n_epochs):\n    print(\"Epoch=\", i+1,\", Train Loss & Accuracy=\",train_whole(),\", Eval Loss & Accuracy=\",eval_whole(),sep=\"\") \n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:29:02.331754Z","iopub.execute_input":"2024-04-28T19:29:02.332603Z","iopub.status.idle":"2024-04-28T19:40:44.933906Z","shell.execute_reply.started":"2024-04-28T19:29:02.332567Z","shell.execute_reply":"2024-04-28T19:40:44.932962Z"},"trusted":true},"execution_count":96,"outputs":[{"name":"stdout","text":"-----------------------Auto Encoder 1------------------------\nEpoch=1, Train Loss=0.022, Eval Loss=0.0082\nEpoch=2, Train Loss=0.0067, Eval Loss=0.0054\nEpoch=3, Train Loss=0.0048, Eval Loss=0.0043\nEpoch=4, Train Loss=0.0039, Eval Loss=0.0036\nEpoch=5, Train Loss=0.0034, Eval Loss=0.0033\nEpoch=6, Train Loss=0.003, Eval Loss=0.0031\nEpoch=7, Train Loss=0.0028, Eval Loss=0.0028\nEpoch=8, Train Loss=0.0026, Eval Loss=0.0027\nEpoch=9, Train Loss=0.0024, Eval Loss=0.0026\nEpoch=10, Train Loss=0.0023, Eval Loss=0.0024\nEpoch=11, Train Loss=0.0021, Eval Loss=0.0023\nEpoch=12, Train Loss=0.002, Eval Loss=0.0021\nEpoch=13, Train Loss=0.002, Eval Loss=0.0021\nEpoch=14, Train Loss=0.0019, Eval Loss=0.0021\nEpoch=15, Train Loss=0.0018, Eval Loss=0.0019\nEpoch=16, Train Loss=0.0018, Eval Loss=0.0019\nEpoch=17, Train Loss=0.0017, Eval Loss=0.0019\nEpoch=18, Train Loss=0.0017, Eval Loss=0.0019\nEpoch=19, Train Loss=0.0016, Eval Loss=0.0018\nEpoch=20, Train Loss=0.0016, Eval Loss=0.0017\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 320x240 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"-----------------------Auto Encoder 2------------------------\nEpoch=1, Train Loss=0.2687, Eval Loss=0.0856\nEpoch=2, Train Loss=0.0651, Eval Loss=0.0534\nEpoch=3, Train Loss=0.0516, Eval Loss=0.0479\nEpoch=4, Train Loss=0.0497, Eval Loss=0.0472\nEpoch=5, Train Loss=0.0488, Eval Loss=0.047\nEpoch=6, Train Loss=0.0485, Eval Loss=0.0465\nEpoch=7, Train Loss=0.0482, Eval Loss=0.0458\nEpoch=8, Train Loss=0.048, Eval Loss=0.0463\nEpoch=9, Train Loss=0.0479, Eval Loss=0.0464\nEpoch=10, Train Loss=0.0477, Eval Loss=0.0457\nEpoch=11, Train Loss=0.0478, Eval Loss=0.0458\nEpoch=12, Train Loss=0.0476, Eval Loss=0.0456\nEpoch=13, Train Loss=0.0476, Eval Loss=0.0458\nEpoch=14, Train Loss=0.0475, Eval Loss=0.0455\nEpoch=15, Train Loss=0.0475, Eval Loss=0.0452\nEpoch=16, Train Loss=0.0475, Eval Loss=0.0457\nEpoch=17, Train Loss=0.0474, Eval Loss=0.0458\nEpoch=18, Train Loss=0.0473, Eval Loss=0.0456\nEpoch=19, Train Loss=0.0473, Eval Loss=0.0458\nEpoch=20, Train Loss=0.0473, Eval Loss=0.0455\n-----------------------Classifier Only------------------------\nEpoch=1, Train Loss & Accuracy=(1.0465, 73.6), Eval Loss & Accuracy=(0.5527, 87.24)\nEpoch=2, Train Loss & Accuracy=(0.4853, 87.93), Eval Loss & Accuracy=(0.4176, 89.15)\nEpoch=3, Train Loss & Accuracy=(0.4008, 89.37), Eval Loss & Accuracy=(0.3609, 90.61)\nEpoch=4, Train Loss & Accuracy=(0.3654, 89.86), Eval Loss & Accuracy=(0.3386, 91.02)\nEpoch=5, Train Loss & Accuracy=(0.3459, 90.37), Eval Loss & Accuracy=(0.3252, 91.06)\nEpoch=6, Train Loss & Accuracy=(0.3345, 90.61), Eval Loss & Accuracy=(0.3165, 91.1)\nEpoch=7, Train Loss & Accuracy=(0.3261, 90.69), Eval Loss & Accuracy=(0.3127, 91.34)\nEpoch=8, Train Loss & Accuracy=(0.3215, 90.88), Eval Loss & Accuracy=(0.3109, 91.36)\nEpoch=9, Train Loss & Accuracy=(0.3168, 91.02), Eval Loss & Accuracy=(0.3102, 91.51)\nEpoch=10, Train Loss & Accuracy=(0.3127, 91.09), Eval Loss & Accuracy=(0.3033, 91.42)\nEpoch=11, Train Loss & Accuracy=(0.3112, 91.1), Eval Loss & Accuracy=(0.3052, 91.39)\nEpoch=12, Train Loss & Accuracy=(0.3088, 91.17), Eval Loss & Accuracy=(0.3014, 91.41)\nEpoch=13, Train Loss & Accuracy=(0.3075, 91.2), Eval Loss & Accuracy=(0.306, 91.38)\nEpoch=14, Train Loss & Accuracy=(0.306, 91.26), Eval Loss & Accuracy=(0.3078, 91.16)\nEpoch=15, Train Loss & Accuracy=(0.3056, 91.19), Eval Loss & Accuracy=(0.2963, 91.56)\nEpoch=16, Train Loss & Accuracy=(0.3031, 91.27), Eval Loss & Accuracy=(0.2982, 91.54)\nEpoch=17, Train Loss & Accuracy=(0.3031, 91.38), Eval Loss & Accuracy=(0.2967, 91.58)\nEpoch=18, Train Loss & Accuracy=(0.3025, 91.35), Eval Loss & Accuracy=(0.3041, 91.41)\nEpoch=19, Train Loss & Accuracy=(0.3023, 91.38), Eval Loss & Accuracy=(0.2983, 91.62)\nEpoch=20, Train Loss & Accuracy=(0.3014, 91.36), Eval Loss & Accuracy=(0.3012, 91.68)\n--------------------Fine-Tuning Whole Metwork------------------\nEpoch=1, Train Loss & Accuracy=(0.245, 93.05), Eval Loss & Accuracy=(0.1529, 95.37)\nEpoch=2, Train Loss & Accuracy=(0.0957, 96.99), Eval Loss & Accuracy=(0.1047, 96.84)\nEpoch=3, Train Loss & Accuracy=(0.0696, 97.86), Eval Loss & Accuracy=(0.0936, 97.38)\nEpoch=4, Train Loss & Accuracy=(0.0542, 98.32), Eval Loss & Accuracy=(0.1241, 96.82)\nEpoch=5, Train Loss & Accuracy=(0.0463, 98.48), Eval Loss & Accuracy=(0.1218, 96.85)\nEpoch=6, Train Loss & Accuracy=(0.0369, 98.73), Eval Loss & Accuracy=(0.1048, 97.58)\nEpoch=7, Train Loss & Accuracy=(0.0342, 98.87), Eval Loss & Accuracy=(0.1015, 97.63)\nEpoch=8, Train Loss & Accuracy=(0.0316, 98.99), Eval Loss & Accuracy=(0.0928, 97.76)\nEpoch=9, Train Loss & Accuracy=(0.0245, 99.18), Eval Loss & Accuracy=(0.1218, 97.5)\nEpoch=10, Train Loss & Accuracy=(0.024, 99.21), Eval Loss & Accuracy=(0.1223, 97.65)\nEpoch=11, Train Loss & Accuracy=(0.023, 99.28), Eval Loss & Accuracy=(0.1305, 97.05)\nEpoch=12, Train Loss & Accuracy=(0.0213, 99.33), Eval Loss & Accuracy=(0.1041, 97.93)\nEpoch=13, Train Loss & Accuracy=(0.0227, 99.3), Eval Loss & Accuracy=(0.1178, 97.64)\nEpoch=14, Train Loss & Accuracy=(0.021, 99.38), Eval Loss & Accuracy=(0.1214, 97.81)\nEpoch=15, Train Loss & Accuracy=(0.0186, 99.44), Eval Loss & Accuracy=(0.1387, 97.7)\nEpoch=16, Train Loss & Accuracy=(0.0163, 99.49), Eval Loss & Accuracy=(0.1281, 97.82)\nEpoch=17, Train Loss & Accuracy=(0.0163, 99.48), Eval Loss & Accuracy=(0.1286, 97.59)\nEpoch=18, Train Loss & Accuracy=(0.0179, 99.44), Eval Loss & Accuracy=(0.134, 97.69)\nEpoch=19, Train Loss & Accuracy=(0.0156, 99.55), Eval Loss & Accuracy=(0.1303, 97.93)\nEpoch=20, Train Loss & Accuracy=(0.0182, 99.48), Eval Loss & Accuracy=(0.1225, 97.86)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}