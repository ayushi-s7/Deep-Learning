{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:52:08.386199Z","iopub.execute_input":"2024-03-20T17:52:08.386535Z","iopub.status.idle":"2024-03-20T17:52:15.551065Z","shell.execute_reply.started":"2024-03-20T17:52:08.386511Z","shell.execute_reply":"2024-03-20T17:52:15.550191Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n  device=torch.device(type=\"cuda\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:52:15.552788Z","iopub.execute_input":"2024-03-20T17:52:15.553253Z","iopub.status.idle":"2024-03-20T17:52:15.587006Z","shell.execute_reply.started":"2024-03-20T17:52:15.553225Z","shell.execute_reply":"2024-03-20T17:52:15.586143Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset=datasets.MNIST(root=\"data\",train=True,download=True,transform=ToTensor())\ntest_dataset=datasets.MNIST(root=\"data\",train=False,download=True,transform=ToTensor())","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:52:15.588719Z","iopub.execute_input":"2024-03-20T17:52:15.589145Z","iopub.status.idle":"2024-03-20T17:52:16.739303Z","shell.execute_reply.started":"2024-03-20T17:52:15.589112Z","shell.execute_reply":"2024-03-20T17:52:16.738333Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 107161352.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 46465551.91it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 1648877/1648877 [00:00<00:00, 24652332.48it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 7611078.21it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size=64\ntrain=DataLoader(\n    dataset=train_dataset,\n    batch_size=batch_size,\n    shuffle=True\n)\ntest=DataLoader(\n    dataset=test_dataset,\n    batch_size=batch_size,\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:52:16.742189Z","iopub.execute_input":"2024-03-20T17:52:16.742641Z","iopub.status.idle":"2024-03-20T17:52:16.748208Z","shell.execute_reply.started":"2024-03-20T17:52:16.742605Z","shell.execute_reply":"2024-03-20T17:52:16.747066Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class vanillanetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1=nn.Linear(in_features=28*28,out_features=512)\n        self.b1=nn.BatchNorm1d(num_features=512)\n        self.layer2=nn.Linear(512,256)\n        self.b2=nn.BatchNorm1d(num_features=256)\n        self.layer3=nn.Linear(256,128)\n        self.b3=nn.BatchNorm1d(num_features=128)\n        self.layer4=nn.Linear(128,64)\n        self.b4=nn.BatchNorm1d(num_features=64)\n        self.layer5=nn.Linear(64,32)\n        self.b5=nn.BatchNorm1d(num_features=32)\n        self.layer6=nn.Linear(32,10)\n        self.b6=nn.BatchNorm1d(num_features=10)\n        self.r=nn.ReLU()\n\n    def forward(self,x):\n        x=self.layer1(x)\n        x=self.b1(x)\n        x=self.r(x)\n        x=self.layer2(x)\n        x=self.b2(x)\n        x=self.r(x)\n        x=self.layer3(x)\n        x=self.b3(x)\n        x=self.r(x)\n        x=self.layer4(x)\n        x=self.b4(x)\n        x=self.r(x)\n        x=self.layer5(x)\n        x=self.b5(x)\n        x=self.r(x)\n        x=self.layer6(x)\n        x=self.b6(x)\n        x=self.r(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:52:16.749387Z","iopub.execute_input":"2024-03-20T17:52:16.749684Z","iopub.status.idle":"2024-03-20T17:52:16.761894Z","shell.execute_reply.started":"2024-03-20T17:52:16.749659Z","shell.execute_reply":"2024-03-20T17:52:16.760970Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def trainmodel(model,train_dataloader,lossfunction,optimizer):\n    model.train()\n    correct=0\n    totaloss=0\n    for i, (img,label) in enumerate(train_dataloader):\n        img=torch.reshape(img,(-1,28*28))\n        img=img.to(device)\n        label=label.to(device)\n        prediction=model(img)\n        loss=lossfunction(prediction,label)\n        totaloss+=loss.item()\n        predictedvalue=torch.argmax(prediction,dim=1)\n        correct+=(predictedvalue==label).sum().item()\n        loss.backward() #backpropogate loss\n        optimizer.step() #update parameters\n        optimizer.zero_grad() #reset gradients to 0 to prevent accumulation\n        \n        if (i%200==0):\n            batchloss=totaloss/(i+1)\n            batchloss=round(batchloss,2)#avg loss for batch\n            batchacc=(correct/((i+1)*batch_size))*100 #correct predictions so far\n            batchacc=round(batchacc,2)\n            print(\"For {0} batch the loss={1} and accuracy:{2}\".format(i+1,batchloss,batchacc))\n            \n    epochloss=totaloss/len(train_dataloader) #avg loss for 1 batch\n    epochloss=round(epochloss,2)\n#     totalimages=len(train_dataloader.dataset)\n    epochaccuracy=(correct/len(train_dataloader.dataset))*100 \n    epochaccuracy=round(epochaccuracy,2)\n    return epochloss,epochaccuracy         ","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:52:16.763085Z","iopub.execute_input":"2024-03-20T17:52:16.763423Z","iopub.status.idle":"2024-03-20T17:52:16.773577Z","shell.execute_reply.started":"2024-03-20T17:52:16.763398Z","shell.execute_reply":"2024-03-20T17:52:16.772630Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def testmodel(model,test_dataloader,lossfunction):\n    model.eval()\n    correct=0\n    totalloss=0\n    with torch.no_grad():\n        for i, (img,label) in enumerate(test_dataloader):\n            img=torch.reshape(img,(-1,28*28))\n            img=img.to(device)\n            label=label.to(device)\n            prediction=model(img)\n            loss=lossfunction(prediction,label)\n            totalloss+=loss.item()\n            predictedvalue=torch.argmax(prediction,dim=1)\n            correct+=(predictedvalue==label).sum().type(torch.float).item()\n\n            if(i%50==0):\n                batchloss=round((totalloss/(i+1)),2)\n                batchacc=(correct/((i+1)*batch_size))*100\n                batchacc=round(batchacc,2)\n                print(\"In testing For {0} batch the loss={1} and accuracy:{2}\".format(i+1,batchloss,batchacc))\n    \n    epochloss=round(totalloss/len(test_dataloader),2)\n    totalimages=len(test_dataloader.dataset)\n    epochacc=correct/totalimages *100\n    epochacc=round(epochacc,2)\n    \n    return epochloss,epochacc\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:52:16.774672Z","iopub.execute_input":"2024-03-20T17:52:16.774921Z","iopub.status.idle":"2024-03-20T17:52:16.790697Z","shell.execute_reply.started":"2024-03-20T17:52:16.774900Z","shell.execute_reply":"2024-03-20T17:52:16.789636Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#main code\nmodel=vanillanetwork()\nmodel=model.to(device)\nlossfunction=nn.CrossEntropyLoss()\noptimizer=torch.optim.Adam(model.parameters(),lr=0.001)\nepochs=20\nfor i in range(epochs):\n    print(\"Epoch number: \",i+1)\n    trainloss,trainacc=trainmodel(model,train,lossfunction,optimizer)\n    print(\"Training epoch loss: \",trainloss,\"Training accuracy: \",trainacc)\n    testloss,testacc=testmodel(model,test,lossfunction)\n    print(\"------------------\")\n    print(\"Testing epoch loss: \",testloss,\"Testing accuracy: \",testacc)\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:52:16.791764Z","iopub.execute_input":"2024-03-20T17:52:16.792025Z","iopub.status.idle":"2024-03-20T17:56:22.235346Z","shell.execute_reply.started":"2024-03-20T17:52:16.792002Z","shell.execute_reply":"2024-03-20T17:56:22.234364Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch number:  1\nFor 1 batch the loss=2.49 and accuracy:9.38\nFor 201 batch the loss=0.69 and accuracy:88.11\nFor 401 batch the loss=0.56 and accuracy:90.7\nFor 601 batch the loss=0.48 and accuracy:91.99\nFor 801 batch the loss=0.43 and accuracy:92.6\nTraining epoch loss:  0.41 Training accuracy:  92.94\nIn testing For 1 batch the loss=0.1 and accuracy:100.0\nIn testing For 51 batch the loss=0.22 and accuracy:95.53\nIn testing For 101 batch the loss=0.2 and accuracy:96.24\nIn testing For 151 batch the loss=0.18 and accuracy:97.03\n------------------\nTesting epoch loss:  0.18 Testing accuracy:  96.96\n\n\nEpoch number:  2\nFor 1 batch the loss=0.16 and accuracy:96.88\nFor 201 batch the loss=0.2 and accuracy:96.42\nFor 401 batch the loss=0.2 and accuracy:96.31\nFor 601 batch the loss=0.2 and accuracy:96.2\nFor 801 batch the loss=0.19 and accuracy:96.27\nTraining epoch loss:  0.18 Training accuracy:  96.27\nIn testing For 1 batch the loss=0.05 and accuracy:100.0\nIn testing For 51 batch the loss=0.14 and accuracy:96.75\nIn testing For 101 batch the loss=0.12 and accuracy:97.22\nIn testing For 151 batch the loss=0.1 and accuracy:97.72\n------------------\nTesting epoch loss:  0.11 Testing accuracy:  97.58\n\n\nEpoch number:  3\nFor 1 batch the loss=0.1 and accuracy:98.44\nFor 201 batch the loss=0.14 and accuracy:97.01\nFor 401 batch the loss=0.14 and accuracy:97.12\nFor 601 batch the loss=0.14 and accuracy:97.12\nFor 801 batch the loss=0.13 and accuracy:97.13\nTraining epoch loss:  0.13 Training accuracy:  97.11\nIn testing For 1 batch the loss=0.04 and accuracy:100.0\nIn testing For 51 batch the loss=0.12 and accuracy:96.88\nIn testing For 101 batch the loss=0.11 and accuracy:97.15\nIn testing For 151 batch the loss=0.09 and accuracy:97.72\n------------------\nTesting epoch loss:  0.09 Testing accuracy:  97.63\n\n\nEpoch number:  4\nFor 1 batch the loss=0.09 and accuracy:98.44\nFor 201 batch the loss=0.1 and accuracy:97.76\nFor 401 batch the loss=0.1 and accuracy:97.65\nFor 601 batch the loss=0.1 and accuracy:97.69\nFor 801 batch the loss=0.1 and accuracy:97.68\nTraining epoch loss:  0.1 Training accuracy:  97.69\nIn testing For 1 batch the loss=0.03 and accuracy:98.44\nIn testing For 51 batch the loss=0.12 and accuracy:96.63\nIn testing For 101 batch the loss=0.11 and accuracy:97.05\nIn testing For 151 batch the loss=0.09 and accuracy:97.63\n------------------\nTesting epoch loss:  0.09 Testing accuracy:  97.58\n\n\nEpoch number:  5\nFor 1 batch the loss=0.03 and accuracy:100.0\nFor 201 batch the loss=0.08 and accuracy:98.07\nFor 401 batch the loss=0.08 and accuracy:97.98\nFor 601 batch the loss=0.08 and accuracy:98.03\nFor 801 batch the loss=0.08 and accuracy:97.99\nTraining epoch loss:  0.08 Training accuracy:  98.01\nIn testing For 1 batch the loss=0.04 and accuracy:98.44\nIn testing For 51 batch the loss=0.11 and accuracy:97.15\nIn testing For 101 batch the loss=0.09 and accuracy:97.52\nIn testing For 151 batch the loss=0.08 and accuracy:97.91\n------------------\nTesting epoch loss:  0.08 Testing accuracy:  97.8\n\n\nEpoch number:  6\nFor 1 batch the loss=0.07 and accuracy:98.44\nFor 201 batch the loss=0.07 and accuracy:98.25\nFor 401 batch the loss=0.07 and accuracy:98.25\nFor 601 batch the loss=0.07 and accuracy:98.23\nFor 801 batch the loss=0.07 and accuracy:98.26\nTraining epoch loss:  0.07 Training accuracy:  98.24\nIn testing For 1 batch the loss=0.07 and accuracy:98.44\nIn testing For 51 batch the loss=0.09 and accuracy:97.37\nIn testing For 101 batch the loss=0.08 and accuracy:97.79\nIn testing For 151 batch the loss=0.06 and accuracy:98.23\n------------------\nTesting epoch loss:  0.07 Testing accuracy:  98.17\n\n\nEpoch number:  7\nFor 1 batch the loss=0.06 and accuracy:98.44\nFor 201 batch the loss=0.05 and accuracy:98.83\nFor 401 batch the loss=0.05 and accuracy:98.68\nFor 601 batch the loss=0.06 and accuracy:98.57\nFor 801 batch the loss=0.06 and accuracy:98.54\nTraining epoch loss:  0.06 Training accuracy:  98.52\nIn testing For 1 batch the loss=0.02 and accuracy:98.44\nIn testing For 51 batch the loss=0.09 and accuracy:97.64\nIn testing For 101 batch the loss=0.08 and accuracy:97.88\nIn testing For 151 batch the loss=0.06 and accuracy:98.3\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.27\n\n\nEpoch number:  8\nFor 1 batch the loss=0.02 and accuracy:98.44\nFor 201 batch the loss=0.05 and accuracy:98.79\nFor 401 batch the loss=0.05 and accuracy:98.75\nFor 601 batch the loss=0.05 and accuracy:98.79\nFor 801 batch the loss=0.05 and accuracy:98.82\nTraining epoch loss:  0.05 Training accuracy:  98.79\nIn testing For 1 batch the loss=0.05 and accuracy:98.44\nIn testing For 51 batch the loss=0.11 and accuracy:96.97\nIn testing For 101 batch the loss=0.09 and accuracy:97.54\nIn testing For 151 batch the loss=0.07 and accuracy:98.1\n------------------\nTesting epoch loss:  0.07 Testing accuracy:  98.03\n\n\nEpoch number:  9\nFor 1 batch the loss=0.08 and accuracy:98.44\nFor 201 batch the loss=0.04 and accuracy:99.04\nFor 401 batch the loss=0.04 and accuracy:98.93\nFor 601 batch the loss=0.04 and accuracy:98.92\nFor 801 batch the loss=0.04 and accuracy:98.81\nTraining epoch loss:  0.05 Training accuracy:  98.8\nIn testing For 1 batch the loss=0.07 and accuracy:96.88\nIn testing For 51 batch the loss=0.1 and accuracy:97.4\nIn testing For 101 batch the loss=0.08 and accuracy:97.83\nIn testing For 151 batch the loss=0.06 and accuracy:98.26\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.21\n\n\nEpoch number:  10\nFor 1 batch the loss=0.01 and accuracy:100.0\nFor 201 batch the loss=0.04 and accuracy:99.04\nFor 401 batch the loss=0.04 and accuracy:99.05\nFor 601 batch the loss=0.04 and accuracy:99.02\nFor 801 batch the loss=0.04 and accuracy:98.99\nTraining epoch loss:  0.04 Training accuracy:  98.97\nIn testing For 1 batch the loss=0.1 and accuracy:96.88\nIn testing For 51 batch the loss=0.1 and accuracy:97.49\nIn testing For 101 batch the loss=0.08 and accuracy:97.88\nIn testing For 151 batch the loss=0.06 and accuracy:98.31\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.25\n\n\nEpoch number:  11\nFor 1 batch the loss=0.01 and accuracy:100.0\nFor 201 batch the loss=0.03 and accuracy:99.22\nFor 401 batch the loss=0.03 and accuracy:99.16\nFor 601 batch the loss=0.03 and accuracy:99.14\nFor 801 batch the loss=0.03 and accuracy:99.14\nTraining epoch loss:  0.03 Training accuracy:  99.06\nIn testing For 1 batch the loss=0.05 and accuracy:98.44\nIn testing For 51 batch the loss=0.08 and accuracy:97.49\nIn testing For 101 batch the loss=0.07 and accuracy:97.83\nIn testing For 151 batch the loss=0.06 and accuracy:98.29\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.19\n\n\nEpoch number:  12\nFor 1 batch the loss=0.0 and accuracy:100.0\nFor 201 batch the loss=0.03 and accuracy:99.29\nFor 401 batch the loss=0.03 and accuracy:99.27\nFor 601 batch the loss=0.03 and accuracy:99.23\nFor 801 batch the loss=0.03 and accuracy:99.22\nTraining epoch loss:  0.03 Training accuracy:  99.17\nIn testing For 1 batch the loss=0.01 and accuracy:100.0\nIn testing For 51 batch the loss=0.09 and accuracy:97.49\nIn testing For 101 batch the loss=0.07 and accuracy:97.88\nIn testing For 151 batch the loss=0.06 and accuracy:98.32\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.32\n\n\nEpoch number:  13\nFor 1 batch the loss=0.06 and accuracy:98.44\nFor 201 batch the loss=0.02 and accuracy:99.46\nFor 401 batch the loss=0.02 and accuracy:99.37\nFor 601 batch the loss=0.02 and accuracy:99.42\nFor 801 batch the loss=0.02 and accuracy:99.42\nTraining epoch loss:  0.02 Training accuracy:  99.36\nIn testing For 1 batch the loss=0.11 and accuracy:98.44\nIn testing For 51 batch the loss=0.09 and accuracy:97.43\nIn testing For 101 batch the loss=0.08 and accuracy:97.87\nIn testing For 151 batch the loss=0.06 and accuracy:98.21\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.18\n\n\nEpoch number:  14\nFor 1 batch the loss=0.01 and accuracy:100.0\nFor 201 batch the loss=0.02 and accuracy:99.36\nFor 401 batch the loss=0.02 and accuracy:99.34\nFor 601 batch the loss=0.02 and accuracy:99.38\nFor 801 batch the loss=0.02 and accuracy:99.37\nTraining epoch loss:  0.02 Training accuracy:  99.35\nIn testing For 1 batch the loss=0.02 and accuracy:98.44\nIn testing For 51 batch the loss=0.1 and accuracy:97.09\nIn testing For 101 batch the loss=0.08 and accuracy:97.6\nIn testing For 151 batch the loss=0.07 and accuracy:98.06\n------------------\nTesting epoch loss:  0.07 Testing accuracy:  98.01\n\n\nEpoch number:  15\nFor 1 batch the loss=0.01 and accuracy:100.0\nFor 201 batch the loss=0.02 and accuracy:99.43\nFor 401 batch the loss=0.02 and accuracy:99.4\nFor 601 batch the loss=0.02 and accuracy:99.38\nFor 801 batch the loss=0.02 and accuracy:99.35\nTraining epoch loss:  0.02 Training accuracy:  99.34\nIn testing For 1 batch the loss=0.1 and accuracy:98.44\nIn testing For 51 batch the loss=0.08 and accuracy:97.67\nIn testing For 101 batch the loss=0.07 and accuracy:98.08\nIn testing For 151 batch the loss=0.05 and accuracy:98.47\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.43\n\n\nEpoch number:  16\nFor 1 batch the loss=0.05 and accuracy:98.44\nFor 201 batch the loss=0.02 and accuracy:99.47\nFor 401 batch the loss=0.02 and accuracy:99.48\nFor 601 batch the loss=0.02 and accuracy:99.51\nFor 801 batch the loss=0.02 and accuracy:99.51\nTraining epoch loss:  0.02 Training accuracy:  99.48\nIn testing For 1 batch the loss=0.01 and accuracy:100.0\nIn testing For 51 batch the loss=0.09 and accuracy:97.7\nIn testing For 101 batch the loss=0.08 and accuracy:98.0\nIn testing For 151 batch the loss=0.06 and accuracy:98.41\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.37\n\n\nEpoch number:  17\nFor 1 batch the loss=0.01 and accuracy:100.0\nFor 201 batch the loss=0.02 and accuracy:99.51\nFor 401 batch the loss=0.02 and accuracy:99.46\nFor 601 batch the loss=0.02 and accuracy:99.45\nFor 801 batch the loss=0.02 and accuracy:99.46\nTraining epoch loss:  0.02 Training accuracy:  99.45\nIn testing For 1 batch the loss=0.01 and accuracy:100.0\nIn testing For 51 batch the loss=0.08 and accuracy:97.98\nIn testing For 101 batch the loss=0.07 and accuracy:98.17\nIn testing For 151 batch the loss=0.06 and accuracy:98.56\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.51\n\n\nEpoch number:  18\nFor 1 batch the loss=0.04 and accuracy:98.44\nFor 201 batch the loss=0.01 and accuracy:99.7\nFor 401 batch the loss=0.01 and accuracy:99.61\nFor 601 batch the loss=0.01 and accuracy:99.65\nFor 801 batch the loss=0.01 and accuracy:99.6\nTraining epoch loss:  0.02 Training accuracy:  99.54\nIn testing For 1 batch the loss=0.07 and accuracy:96.88\nIn testing For 51 batch the loss=0.09 and accuracy:97.58\nIn testing For 101 batch the loss=0.08 and accuracy:97.94\nIn testing For 151 batch the loss=0.06 and accuracy:98.43\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.34\n\n\nEpoch number:  19\nFor 1 batch the loss=0.0 and accuracy:100.0\nFor 201 batch the loss=0.02 and accuracy:99.57\nFor 401 batch the loss=0.02 and accuracy:99.57\nFor 601 batch the loss=0.02 and accuracy:99.53\nFor 801 batch the loss=0.02 and accuracy:99.51\nTraining epoch loss:  0.02 Training accuracy:  99.53\nIn testing For 1 batch the loss=0.09 and accuracy:98.44\nIn testing For 51 batch the loss=0.08 and accuracy:97.98\nIn testing For 101 batch the loss=0.07 and accuracy:98.24\nIn testing For 151 batch the loss=0.05 and accuracy:98.54\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.5\n\n\nEpoch number:  20\nFor 1 batch the loss=0.01 and accuracy:100.0\nFor 201 batch the loss=0.01 and accuracy:99.67\nFor 401 batch the loss=0.01 and accuracy:99.65\nFor 601 batch the loss=0.01 and accuracy:99.64\nFor 801 batch the loss=0.02 and accuracy:99.6\nTraining epoch loss:  0.02 Training accuracy:  99.59\nIn testing For 1 batch the loss=0.09 and accuracy:98.44\nIn testing For 51 batch the loss=0.09 and accuracy:97.46\nIn testing For 101 batch the loss=0.07 and accuracy:98.0\nIn testing For 151 batch the loss=0.06 and accuracy:98.39\n------------------\nTesting epoch loss:  0.06 Testing accuracy:  98.33\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}